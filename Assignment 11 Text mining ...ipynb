{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45da0c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea5e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download ('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05eb5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\sushi\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\sushi\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\sushi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\sushi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sushi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sushi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sushi\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f90686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1254e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text\n",
       "0           1                             @kunalb11 Im an alien\n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
       "2           3                @joerogan @Spotify Great interview!\n",
       "3           4                    @gtera27 Doge is underestimated\n",
       "4           5  @teslacn Congratulations Tesla China for amazi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/Sushi/Downloads/Elon_musk.csv\",encoding=\"latin-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a5c2b",
   "metadata": {},
   "source": [
    "# Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdfbc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  word_count\n",
       "0                             @kunalb11 Im an alien           4\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          13\n",
       "2                @joerogan @Spotify Great interview!           4\n",
       "3                    @gtera27 Doge is underestimated           4\n",
       "4  @teslacn Congratulations Tesla China for amazi...          17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Words in single tweet\n",
    "data['word_count'] = data['Text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['Text','word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb5672",
   "metadata": {},
   "source": [
    "#  Number of Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "668122fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  char_count\n",
       "0                             @kunalb11 Im an alien          22\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          82\n",
       "2                @joerogan @Spotify Great interview!          35\n",
       "3                    @gtera27 Doge is underestimated          31\n",
       "4  @teslacn Congratulations Tesla China for amazi...         104"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of characters in single tweet\n",
    "data['char_count'] = data['Text'].str.len() ## this also includes spaces\n",
    "data[['Text','char_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfb7c4",
   "metadata": {},
   "source": [
    "# Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b71c935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>5.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>5.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  avg_word\n",
       "0                             @kunalb11 Im an alien  4.750000\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...  5.384615\n",
       "2                @joerogan @Spotify Great interview!  8.000000\n",
       "3                    @gtera27 Doge is underestimated  7.000000\n",
       "4  @teslacn Congratulations Tesla China for amazi...  5.176471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['Text'].apply(lambda x: avg_word(x))\n",
    "data[['Text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78bce44",
   "metadata": {},
   "source": [
    "# Number of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0c0120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  stopwords\n",
       "0                             @kunalb11 Im an alien          1\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          4\n",
       "2                @joerogan @Spotify Great interview!          0\n",
       "3                    @gtera27 Doge is underestimated          1\n",
       "4  @teslacn Congratulations Tesla China for amazi...          5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stopwords'] = data['Text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data[['Text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387bca7",
   "metadata": {},
   "source": [
    "# Number of Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e557b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  hastags\n",
       "0                             @kunalb11 Im an alien        1\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...        1\n",
       "2                @joerogan @Spotify Great interview!        2\n",
       "3                    @gtera27 Doge is underestimated        1\n",
       "4  @teslacn Congratulations Tesla China for amazi...        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hastags'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))\n",
    "data[['Text','hastags']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b2ca1",
   "metadata": {},
   "source": [
    "# Number of Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f23578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  numerics\n",
       "0                             @kunalb11 Im an alien         0\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...         0\n",
       "2                @joerogan @Spotify Great interview!         0\n",
       "3                    @gtera27 Doge is underestimated         0\n",
       "4  @teslacn Congratulations Tesla China for amazi...         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['numerics'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data[['Text','numerics']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4242b21",
   "metadata": {},
   "source": [
    "# Number of Upper Case Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9243b63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  upper\n",
       "0                             @kunalb11 Im an alien      0\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...      1\n",
       "2                @joerogan @Spotify Great interview!      0\n",
       "3                    @gtera27 Doge is underestimated      0\n",
       "4  @teslacn Congratulations Tesla China for amazi...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['upper'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "data[['Text','upper']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd878c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               @kunalb11 im an alien\n",
       "1    @id_aa_carmack ray tracing on cyberpunk with h...\n",
       "2                  @joerogan @spotify great interview!\n",
       "3                      @gtera27 doge is underestimated\n",
       "4    @teslacn congratulations tesla china for amazi...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "763d2d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sushi\\AppData\\Local\\Temp/ipykernel_21288/1947507549.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['Text'] = data['Text'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                 kunalb11 im an alien\n",
       "1    id_aa_carmack ray tracing on cyberpunk with hd...\n",
       "2                     joerogan spotify great interview\n",
       "3                       gtera27 doge is underestimated\n",
       "4    teslacn congratulations tesla china for amazin...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].str.replace('[^\\w\\s]','')\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0421e",
   "metadata": {},
   "source": [
    "# Removal of Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21467d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                     joerogan spotify great interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations tesla china amazing ex...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80835cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacex            239\n",
       "amp               218\n",
       "tesla             166\n",
       "erdayastronaut    142\n",
       "rt                127\n",
       "ppathole          123\n",
       "flcnhvy           114\n",
       "yes                86\n",
       "great              76\n",
       "teslaownerssv      73\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['Text']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c5e3e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "081004d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nyquil                1\n",
       "musk                  1\n",
       "negati                1\n",
       "httpstco6ohta09s5l    1\n",
       "carousel              1\n",
       "joeingeneral          1\n",
       "andrewbogut           1\n",
       "typical               1\n",
       "unusual               1\n",
       "altho                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['Text']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d160330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b537b5b3",
   "metadata": {},
   "source": [
    "# Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eae2197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 in alien\n",
       "1    id_aa_carmack ray tracing cyberpunk her nextle...\n",
       "2                           joerogan specify interview\n",
       "3                          gtera27 done underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be772034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5619abda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray trace cyberpunk hdr nextleve...\n",
       "2                           joerogan spotifi interview\n",
       "3                              gtera27 doge underestim\n",
       "4    teslacn congratul china amaz execut last year ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "data['Text'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b4ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed441938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulation china amazing execution...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb020231",
   "metadata": {},
   "source": [
    "#  Advanced Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5a663",
   "metadata": {},
   "source": [
    "#  N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e10a7883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['kunalb11', 'im']), WordList(['im', 'alien'])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(data['Text'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439a2b4",
   "metadata": {},
   "source": [
    "# Term frequency\n",
    "Term frequency is simply the ratio of the count of a word present in a sentence, to the length of the sentence.\n",
    "\n",
    "Therefore, we can generalize term frequency as:\n",
    "\n",
    "TF = (Number of times term T appears in the particular row) / (number of terms in that row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee2fb614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tracing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf\n",
       "0  id_aa_carmack   1\n",
       "1            ray   1\n",
       "2        tracing   1\n",
       "3      cyberpunk   1\n",
       "4            hdr   1\n",
       "5      nextlevel   1\n",
       "6          tried   1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = (data['Text'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb462084",
   "metadata": {},
   "source": [
    "#  Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4e27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "      <td>4.166415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "      <td>5.035453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tracing</td>\n",
       "      <td>1</td>\n",
       "      <td>7.600402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "      <td>5.115496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "      <td>5.808643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf       idf\n",
       "0  id_aa_carmack   1  4.166415\n",
       "1            ray   1  5.035453\n",
       "2        tracing   1  7.600402\n",
       "3      cyberpunk   1  5.115496\n",
       "4            hdr   1  6.907255\n",
       "5      nextlevel   1  6.907255\n",
       "6          tried   1  5.808643"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,word in enumerate(tf1['words']):\n",
    "  tf1.loc[i, 'idf'] = np.log(data.shape[0]/(len(data[data['Text'].str.contains(word)])))\n",
    "\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271277a5",
   "metadata": {},
   "source": [
    "# Term Frequency – Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "vect = tfidf.fit_transform(data['Text'])\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979663a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "data_bow = bow.fit_transform(data['Text'])\n",
    "data_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940bdd3a",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88016a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'][:5].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['Text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "data[['Text','sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2cf43",
   "metadata": {},
   "source": [
    "# Perform emotion mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279af461",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import matplotlib\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1212c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"positive-words.txt\", \"r\", encoding=\"utf-8\") as p:\n",
    "    pos = p.read()\n",
    "    print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"stop.txt\" ,\"r\", encoding=\"ISO-8859-1\") as s:\n",
    "    stop = s.read()\n",
    "    print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ca70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('negative-words (1).txt' , \"r\", encoding=\"ISO-8859-1\") as n:\n",
    "    neg = n.read()\n",
    "    print(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008adf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
